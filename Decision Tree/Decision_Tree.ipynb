{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0363ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f12828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node class\n",
    "class Node:\n",
    "    def __init__(self,value=None,left=None,right=None,feature=None,threshold=None):\n",
    "        self.value = value \n",
    "        self.left  = left\n",
    "        self.right = right\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def is_leaf_node(self):\n",
    "        return not self.left and not self.right \n",
    "\n",
    "# decision tree implementation\n",
    "class Decision_Tree:\n",
    "    \n",
    "    def __init__(self,max_depth=5,min_samples_split=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.root = None\n",
    "        \n",
    "    def common_label(self,y):\n",
    "        \n",
    "        if len(y)==0:\n",
    "            return None\n",
    "        count = np.bincount(y)\n",
    "        return np.argmax(count)\n",
    "    \n",
    "    def gini_impurity(self,y):\n",
    "        if len(y)==0:\n",
    "            return 0\n",
    "        counts = np.bincount(y)\n",
    "        probs = counts/len(y)\n",
    "        return 1-np.sum(probs**2)\n",
    "    \n",
    "    def entropy__(self,y):\n",
    "        if len(y)==0:\n",
    "            return 0\n",
    "        counts = np.bincount(y)\n",
    "        probs = counts/len(y)\n",
    "        return -np.sum(probs * np.log2(probs + 1e-9))\n",
    "    \n",
    "    \n",
    "        \n",
    "    def best_split_(self,X,y):\n",
    "        \n",
    "        best_feature,best_threshold,best_gain = None,None,-1\n",
    "        parent_impurity = self.entropy__(y)\n",
    "        samples,features = X.shape\n",
    "        \n",
    "        for feature in range(features):\n",
    "            thresholds = np.unique(X[:,feature])\n",
    "            for threshold in thresholds:\n",
    "                left_idx = X[:,feature] <=threshold\n",
    "                right_idx = X[:,feature] > threshold\n",
    "                \n",
    "                if np.sum(left_idx) == 0 or np.sum(right_idx) == 0:\n",
    "                    continue\n",
    "                \n",
    "                left_gini  = self.entropy__(y[left_idx])\n",
    "                right_gini = self.entropy__(y[right_idx])\n",
    "                \n",
    "                weighted_gini = (len(y[left_idx]) * left_gini + len(y[right_idx]) * right_gini) / len(y)\n",
    "                \n",
    "                information_gain = parent_impurity - weighted_gini\n",
    "                \n",
    "                if information_gain > best_gain:\n",
    "                    best_gain = information_gain\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "        return (best_feature,best_threshold)\n",
    "                    \n",
    "        \n",
    "        \n",
    "    def grow_tree_(self,X,y,depth=0):\n",
    "        \n",
    "        samples = len(y)\n",
    "        labels = len(np.unique(y))\n",
    "        \n",
    "        # pre-pruning\n",
    "        if depth >= self.max_depth or labels==1 or samples <=self.min_samples_split:\n",
    "            leaf_val = self.common_label(y)\n",
    "            return Node(value=leaf_val)\n",
    "        \n",
    "        feature,threshold = self.best_split_(X,y)\n",
    "        \n",
    "        if feature is None:\n",
    "            return Node(value = self.common_label(y))\n",
    "        \n",
    "        \n",
    "        left_idx = X[:, feature] <= threshold\n",
    "        right_idx = X[:, feature] > threshold\n",
    "        \n",
    "        left = self.grow_tree_(X[left_idx],y[left_idx],depth+1)\n",
    "        right = self.grow_tree_(X[right_idx],y[right_idx],depth+1)\n",
    "        \n",
    "        return Node(feature=feature,threshold=threshold,left=left,right=right)\n",
    "    \n",
    "    def traverse_tree(self,X,node):\n",
    "        \n",
    "        if node and node.is_leaf_node():\n",
    "            return node.value\n",
    "        \n",
    "        if X[node.feature] <= node.threshold:    \n",
    "            return self.traverse_tree(X,node.left)\n",
    "        else:\n",
    "            return self.traverse_tree(X,node.right)\n",
    "            \n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        self.root = self.grow_tree_(X,y)\n",
    "    \n",
    "    \n",
    "    def predict(self,X):\n",
    "        return np.array([self.traverse_tree(x,self.root) for x in X])\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd32821",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import  DecisionTreeClassifier\n",
    "\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data  # shape: (150, 4)\n",
    "y = iris.target  # shape: (150,)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Fit your Decision_Tree\n",
    "model = DecisionTreeClassifier(max_depth=1,min_samples_split=10)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "acc = np.sum(preds == y_test) / len(y_test)\n",
    "print(f\"Accuracy: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6b734c",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data  # shape: (150, 4)\n",
    "y = iris.target  # shape: (150,)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Fit your Decision_Tree\n",
    "tree = Decision_Tree(max_depth=1, min_samples_split=10)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "preds = tree.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "acc = np.sum(preds == y_test) / len(y_test)\n",
    "print(f\"Accuracy: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0bdd83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04616cf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
